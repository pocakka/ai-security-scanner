# Playwright Analyzer Architecture

**Purpose:** Replace mock crawler with real browser automation for passive security analysis

---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Worker Process                        â”‚
â”‚                     (src/lib/worker.ts)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Playwright Crawler                         â”‚
â”‚              (src/lib/playwright-crawler.ts)                 â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Browser Launch (Chromium, headless: true)        â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                      â”‚                                       â”‚
â”‚                      â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Network Monitoring Layer                          â”‚    â”‚
â”‚  â”‚  - Intercept all requests/responses                â”‚    â”‚
â”‚  â”‚  - Capture headers, status codes, URLs             â”‚    â”‚
â”‚  â”‚  - Identify AI provider endpoints                  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                      â”‚                                       â”‚
â”‚                      â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Page Navigation                                   â”‚    â”‚
â”‚  â”‚  - Load target URL                                 â”‚    â”‚
â”‚  â”‚  - Wait for network idle                           â”‚    â”‚
â”‚  â”‚  - Handle errors/timeouts                          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                      â”‚                                       â”‚
â”‚                      â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Data Collection                                   â”‚    â”‚
â”‚  â”‚  - DOM snapshot                                    â”‚    â”‚
â”‚  â”‚  - Cookies                                         â”‚    â”‚
â”‚  â”‚  - JavaScript evaluation                           â”‚    â”‚
â”‚  â”‚  - Screenshot (optional)                           â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                      â”‚                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Analyzer Pipeline                        â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ AI Provider    â”‚  â”‚ AI Framework   â”‚  â”‚ Client-Side  â”‚ â”‚
â”‚  â”‚ Detector       â”‚  â”‚ Detector       â”‚  â”‚ AI Risk      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ SSL/TLS        â”‚  â”‚ Cookie         â”‚  â”‚ Header       â”‚ â”‚
â”‚  â”‚ Analyzer       â”‚  â”‚ Analyzer       â”‚  â”‚ Analyzer     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚ Library        â”‚  â”‚ Server         â”‚                    â”‚
â”‚  â”‚ Detector       â”‚  â”‚ Analyzer       â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Report Generator                          â”‚
â”‚              (src/lib/report-generator.ts)                   â”‚
â”‚                                                              â”‚
â”‚  - Risk scoring (0-100)                                     â”‚
â”‚  - Findings aggregation                                     â”‚
â”‚  - JSON report structure                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ File Structure

```
src/lib/
â”œâ”€â”€ playwright-crawler.ts       # Main crawler class
â”œâ”€â”€ crawler-config.ts            # Configuration constants
â”œâ”€â”€ worker.ts                    # Modified to use real crawler
â”œâ”€â”€ mock-crawler.ts              # Keep for testing mode
â”‚
â”œâ”€â”€ analyzers/
â”‚   â”œâ”€â”€ ai-provider-detector.ts  # Network-based AI detection
â”‚   â”œâ”€â”€ ai-framework-detector.ts # DOM-based framework detection
â”‚   â”œâ”€â”€ client-ai-risk-analyzer.ts # JS code analysis
â”‚   â”œâ”€â”€ ssl-analyzer.ts          # Certificate & TLS analysis
â”‚   â”œâ”€â”€ cookie-analyzer.ts       # Cookie security audit
â”‚   â”œâ”€â”€ header-analyzer.ts       # Enhanced header checks
â”‚   â”œâ”€â”€ library-detector.ts      # JS library detection
â”‚   â””â”€â”€ server-analyzer.ts       # Server fingerprinting
â”‚
â””â”€â”€ types/
    â””â”€â”€ crawler-types.ts         # TypeScript interfaces
```

---

## ğŸ”§ Core Components

### 1. Playwright Crawler (`playwright-crawler.ts`)

**Responsibilities:**
- Launch headless Chromium browser
- Navigate to target URL
- Monitor network traffic
- Collect page data (DOM, cookies, headers)
- Handle errors and timeouts
- Close browser gracefully

**Interface:**
```typescript
interface CrawlerResult {
  url: string
  statusCode: number

  // Network data
  requests: NetworkRequest[]
  responses: NetworkResponse[]

  // Page data
  html: string
  cookies: Cookie[]
  screenshot?: Buffer

  // Metadata
  loadTime: number
  error?: string
}

interface NetworkRequest {
  url: string
  method: string
  headers: Record<string, string>
  timestamp: number
}

interface NetworkResponse {
  url: string
  statusCode: number
  headers: Record<string, string>
  timestamp: number
}

class PlaywrightCrawler {
  async crawl(url: string): Promise<CrawlerResult>
  private setupNetworkMonitoring(): void
  private handleTimeout(): void
  private captureScreenshot(): Promise<Buffer>
}
```

**Key Features:**
- **Timeout:** 60 seconds max
- **Headless:** Always true (no GUI)
- **User Agent:** Configurable (default: modern Chrome)
- **Network Idle:** Wait for `networkidle` state
- **Error Handling:** Graceful degradation on failures

---

### 2. Network Monitoring Layer

**Implementation in Playwright:**
```typescript
page.on('request', (request) => {
  this.requests.push({
    url: request.url(),
    method: request.method(),
    headers: request.headers(),
    timestamp: Date.now(),
  })
})

page.on('response', async (response) => {
  this.responses.push({
    url: response.url(),
    statusCode: response.status(),
    headers: response.headers(),
    timestamp: Date.now(),
  })
})
```

**Use Cases:**
- AI provider detection (Azure OpenAI, AWS Bedrock URLs)
- Third-party service detection
- API endpoint discovery
- CORS header analysis
- Rate limiting header detection

---

### 3. Data Collection Strategy

**What to collect:**

| Data Type | Method | Storage |
|-----------|--------|---------|
| HTML | `page.content()` | String |
| Cookies | `context.cookies()` | JSON array |
| Screenshot | `page.screenshot()` | Buffer (optional) |
| Network logs | Event listeners | JSON array |
| JS variables | `page.evaluate()` | JSON object |

**Example - JS variable extraction:**
```typescript
const clientData = await page.evaluate(() => {
  return {
    // AI frameworks
    hasLangChain: typeof window.LangChain !== 'undefined',
    hasOpenAI: typeof window.OpenAI !== 'undefined',

    // Libraries
    jQueryVersion: window.jQuery?.fn?.jquery,
    reactVersion: window.React?.version,

    // Custom detection
    aiEndpoints: window.__AI_CONFIG__ // If exposed
  }
})
```

---

## ğŸ” Analyzer Pipeline Design

### Analyzer Base Class

```typescript
abstract class BaseAnalyzer {
  abstract name: string

  abstract analyze(data: CrawlerResult): Promise<AnalyzerResult>

  protected createFinding(
    severity: 'LOW' | 'MEDIUM' | 'HIGH' | 'CRITICAL',
    title: string,
    description: string,
    recommendation: string
  ): Finding {
    return { severity, title, description, recommendation }
  }
}

interface AnalyzerResult {
  analyzerName: string
  findings: Finding[]
  metadata?: Record<string, any>
}
```

### Analyzer Execution

```typescript
// Sequential execution (order matters for dependencies)
const analyzers = [
  new AIProviderDetector(),
  new AIFrameworkDetector(),
  new ClientAIRiskAnalyzer(),
  new SSLAnalyzer(),
  new CookieAnalyzer(),
  new HeaderAnalyzer(),
  new LibraryDetector(),
  new ServerAnalyzer(),
]

const results = []
for (const analyzer of analyzers) {
  try {
    const result = await analyzer.analyze(crawlerResult)
    results.push(result)
  } catch (error) {
    console.error(`Analyzer ${analyzer.name} failed:`, error)
    // Continue with other analyzers
  }
}
```

---

## ğŸ¯ AI Provider Detection Logic

**Network URL Patterns:**

```typescript
const AI_PROVIDER_PATTERNS = {
  'OpenAI': [
    /api\.openai\.com/,
    /openai\.azure\.com/,
  ],
  'Anthropic Claude': [
    /api\.anthropic\.com/,
  ],
  'Azure OpenAI': [
    /.*\.openai\.azure\.com/,
  ],
  'AWS Bedrock': [
    /bedrock-runtime\..*\.amazonaws\.com/,
  ],
  'Google Vertex AI': [
    /.*\.aiplatform\.googleapis\.com/,
    /generativelanguage\.googleapis\.com/,
  ],
  'Cohere': [
    /api\.cohere\.ai/,
  ],
  'HuggingFace': [
    /api-inference\.huggingface\.co/,
  ],
  'Replicate': [
    /api\.replicate\.com/,
  ],
  'Stability AI': [
    /api\.stability\.ai/,
  ],
  'ElevenLabs': [
    /api\.elevenlabs\.io/,
  ],
}

function detectAIProviders(responses: NetworkResponse[]): string[] {
  const detected = new Set<string>()

  for (const response of responses) {
    for (const [provider, patterns] of Object.entries(AI_PROVIDER_PATTERNS)) {
      if (patterns.some(pattern => pattern.test(response.url))) {
        detected.add(provider)
      }
    }
  }

  return Array.from(detected)
}
```

---

## ğŸ”’ Security Considerations

### Crawler Safety
- âœ… **Headless only** - No GUI, no user interaction
- âœ… **No form submissions** - Read-only analysis
- âœ… **No cookies persistence** - Incognito mode
- âœ… **No login attempts** - Public pages only
- âœ… **Timeout enforcement** - Max 60s per page
- âœ… **Resource limits** - Block unnecessary resources

### Resource Blocking (Performance Optimization)

```typescript
await page.route('**/*', (route) => {
  const url = route.request().url()

  // Block heavy resources we don't need
  if (
    url.endsWith('.mp4') ||
    url.endsWith('.webm') ||
    url.endsWith('.mp3') ||
    url.includes('youtube.com/embed')
  ) {
    route.abort()
  } else {
    route.continue()
  }
})
```

---

## âš¡ Performance Optimization

### Strategies:
1. **Parallel scanning (future)** - Multiple workers
2. **Resource blocking** - Skip videos, images (if not needed)
3. **Smart caching** - Cache results for 24h per domain
4. **Timeout tuning** - Adjust based on site complexity
5. **Incremental loading** - Don't wait for all resources

### Expected Performance:
- **Typical scan:** 5-15 seconds
- **Complex site:** 20-40 seconds
- **Timeout:** 60 seconds max

---

## ğŸ§ª Testing Strategy

### Unit Tests
```typescript
// Test individual analyzers
describe('AIProviderDetector', () => {
  it('should detect Azure OpenAI from network logs', async () => {
    const mockResult = {
      responses: [
        { url: 'https://my-resource.openai.azure.com/openai/deployments' }
      ]
    }

    const analyzer = new AIProviderDetector()
    const result = await analyzer.analyze(mockResult)

    expect(result.metadata.providers).toContain('Azure OpenAI')
  })
})
```

### Integration Tests
```typescript
// Test full crawler + analyzer pipeline
describe('Full Scan Pipeline', () => {
  it('should scan OpenAI ChatGPT and detect OpenAI API', async () => {
    const crawler = new PlaywrightCrawler()
    const result = await crawler.crawl('https://chat.openai.com')

    const analyzer = new AIProviderDetector()
    const findings = await analyzer.analyze(result)

    expect(findings.metadata.providers).toContain('OpenAI')
  })
})
```

### Test Sites
- `chat.openai.com` - OpenAI detection
- `claude.ai` - Anthropic detection
- `badssl.com` - SSL issues
- `example.com` - Basic functionality

---

## ğŸš€ Implementation Plan

### Phase 1: Core Crawler (Day 1)
1. âœ… Install Playwright: `npm install playwright`
2. âœ… Run `npx playwright install chromium`
3. âœ… Create `PlaywrightCrawler` class
4. âœ… Implement basic navigation
5. âœ… Add network monitoring
6. âœ… Test with simple URL

### Phase 2: AI Provider Detection (Day 2)
1. âœ… Create `AIProviderDetector` analyzer
2. âœ… Implement pattern matching
3. âœ… Test with known AI sites
4. âœ… Update report generator

### Phase 3: AI Framework Detection (Day 3)
1. âœ… Create `AIFrameworkDetector` analyzer
2. âœ… Implement DOM/JS analysis
3. âœ… Test with framework examples

### Phase 4: Integration (Day 4-5)
1. âœ… Integrate all analyzers
2. âœ… Update worker to use real crawler
3. âœ… Add feature flag (mock vs real)
4. âœ… Update database schema
5. âœ… Update PDF generator

---

## ğŸ”€ Mock vs Real Crawler Toggle

**Environment variable approach:**

```typescript
// .env
USE_REAL_CRAWLER=true  # Set to false for testing

// worker.ts
const crawler = process.env.USE_REAL_CRAWLER === 'true'
  ? new PlaywrightCrawler()
  : new MockCrawler()

const result = await crawler.crawl(url)
```

**Benefits:**
- Easy testing without real browser
- Faster CI/CD pipelines
- Localhost development without Playwright setup

---

## ğŸ“Š Data Flow

```
User submits URL
       â†“
Queue job created (BullMQ)
       â†“
Worker picks up job
       â†“
Playwright crawler launches
       â†“
Browser navigates to URL
       â†“
Network monitoring active
       â†“
Page loads (wait for network idle)
       â†“
Data collection:
  - HTML content
  - Cookies
  - Network logs
  - JS evaluation
       â†“
Close browser
       â†“
Run analyzer pipeline:
  1. AI Provider Detector
  2. AI Framework Detector
  3. Client AI Risk Analyzer
  4. SSL Analyzer
  5. Cookie Analyzer
  6. Header Analyzer
  7. Library Detector
  8. Server Analyzer
       â†“
Aggregate findings
       â†“
Calculate risk score
       â†“
Generate report structure
       â†“
Save to database
       â†“
Update scan status: COMPLETED
       â†“
User views results
```

---

## ğŸ¯ Success Criteria

Sprint 4A is successful when:
- âœ… Playwright crawler works with real websites
- âœ… Network monitoring captures all requests/responses
- âœ… AI providers detected correctly (10+ providers)
- âœ… Scan completes in < 60 seconds for typical sites
- âœ… Error handling prevents crashes
- âœ… Results match or exceed mock crawler quality

---

**Next Steps:** Install Playwright and start Day 1 implementation! ğŸš€
